# Baseline Record: 2026-02-14 (RTX 3060, Qwen2.5-0.5B)

Status: reference baseline  
Scope: local machine, single GPU, sanitized log

## Environment

- GPU: NVIDIA GeForce RTX 3060 (12 GB)
- Driver: 570.133.07
- CUDA runtime (reported by `nvidia-smi`): 12.8
- Python: 3.12.12 (`uv` virtualenv)
- Key packages:
  - `torch==2.9.1+cu128`
  - `transformers==4.57.3`
  - `flashinfer==0.5.3`
  - `sgl-kernel==0.3.21`
  - `minisgl==0.1.0`

## Model

- `Qwen/Qwen2.5-0.5B-Instruct`

## Offline Baseline (`LLM` path)

Command flow: see `../RUNBOOK.md` section "Offline Baseline".

Observed:

- `init_time_s = 161.01`
- `warmup_time_s = 0.08` (`warmup_tokens = 15`)
- `single_req_time_s = 0.24` (`single_out_tokens = 63`)
- Batch run:
  - `batch_num_reqs = 16`
  - `batch_total_out_tokens = 1008`
  - `batch_time_s = 0.38`
  - `batch_out_tok_per_s = 2647.09`

## Online Baseline (server + API path)

Server and client commands: see `../RUNBOOK.md` section "Online Baseline".

Observed:

- Warmup:
  - `warmup_elapsed_s = 0.109`
  - `tokens = 16`
- Benchmark (`batch_size = 8`, output length 64 each):
  - `bench_wall_time_s = 1.247`
  - `Num requests = 8`
  - `Num tokens = 520`
  - `TTFT avg = 959.12 ms`
  - `TPOT avg = 4.3730 ms`
  - `E2E avg = 1.2346 s`
  - `Duration = 1.2368 s`
  - `Throughput = 420.43 token/s`
  - `Req/s = 6.4682`

## Usage

Use these numbers as baseline gates for Rust CPU-side changes:

- Parity first (no correctness regressions).
- Then performance target:
  - initial: `>= +10%` on targeted hot paths
  - milestone: `+20% to +30%` system throughput vs this baseline.
